# Web-Scraping学习笔记

## 前言

&emsp;&emsp;网络爬虫（Web crawler），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本，它们被广泛用于互联网搜索引擎或其他类似网站，可以自动采集所有其能够访问到的页面内容，以获取或更新这些网站的内容和检索方式。从功能上来讲，爬虫一般分为数据采集，处理，储存三个部分。

&emsp;&emsp;本模块学习过程中，我们主要关注数据的采集这一步骤，处理和储存分别由[数据处理](https://github.com/AFT-PKU/Data-Analysis)和[SQL](https://github.com/AFT-PKU/SQL)承担。由于相关书籍比较冗长，而爬虫技术又是一个比较specific技术，我们主要根据较新的[Web-Scraping](Web-Scraping)这一笔记进行学习并进一步实战，同时也特别感谢 @路飞学城IT 提供的[学习视频](https://www.bilibili.com/video/BV1i54y1h75W?p=1)和[相关代码](https://pan.baidu.com/s/101rKi4ZYytMsaT3cYd0B4A)。

&emsp;&emsp;除了学习视频之外，我们也推荐其他一些学习资料：[《Python爬虫开发与项目实战》](Python网络数据采集.pdf)，[requests文档](https://docs.python-requests.org/zh_CN/latest/)，[《Python3网络爬虫开发实战》](https://pan.baidu.com/s/1QDsG1jupCmXWS_J5O45-9g)，[《Python爬虫开发与项目实战》](https://pan.baidu.com/s/1xiMej4cuhlrw9Sxv_hhFSw)


致谢
--------------------
我们分为两个类别的贡献者。
 - 负责人也就是对应的该章节案例维护者。
 - 贡献者对应于主要的案例开发者。

| 学习时间 | 原书章节 | 对应案例  | 小组 | 贡献者 |
| ------------ | ------------ | ------------ | ------------ | ------------ |
| 03.23 | 第零章 爬虫导论 | [爬虫导论](https://github.com/AFT-PKU/PyShare/blob/master/%E5%86%85%E5%9F%B9%E8%B5%84%E6%96%99/20201210-%E7%AC%AC%E4%BA%94%E6%AC%A1%E5%86%85%E5%9F%B9-%E7%88%AC%E8%99%AB/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86.pdf) |  | 高经纬 |
| 04.01 | 第一章  | [第一章]() | 1 | |
| 04.02-04.12 | 第二章 | [第二章]() | 2  |  |
| 04.02-04.12 | 第三章 | [第三章 ]() | 3  | |
| 04.13-04.19 | 第四章 | [第四章]() | 4 | |
| 04.20-04.26 | 第五章 | [第五章]() |  5 |  |


还有很多同学提出了不少建议，我们都列在此处。

@CharlieSCC  ...

如有遗漏，请务必通知我们，可以发邮件至`pkuscc@stu.pku.edu.cn`。
这是我们必须要感谢的，所以不要不好意思。
